{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c951c-6fe1-46ef-b09a-203f005ce0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93bae8-4505-413f-8b6b-6b58332432c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39974c-1d3a-46a5-8ad1-0077ff404e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire contenant les fichiers CSV\n",
    "dir_path = \"ref\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd93e45-5607-4585-bdeb-b8af146f16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms de fichiers CSV dans le répertoire\n",
    "file_names = [f for f in os.listdir(dir_path) if f.endswith('.csv')]\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716db33e-900a-405c-98d6-ccc8d0764276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des DataFrames chargés à partir des fichiers CSV\n",
    "dfs = []\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(dir_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(df.columns[[0,-2,-3]], axis=1)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda80e0-a0ca-4419-9e27-67285ff48477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les DataFrames en un seul DataFrame\n",
    "df_concat = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc341b-2151-4de6-8a20-c598c0c5cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 5 premières lignes du DataFrame concaténé\n",
    "print(df_concat.head())\n",
    "print(df_concat.columns)\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0daf91-a5c0-4fdf-9595-7d7703e420b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utiliser la méthode isna() pour vérifier chaque cellule du dataframe\n",
    "nan_df = df_concat.isna()\n",
    "\n",
    "# Utiliser la méthode sum() pour compter le nombre total de valeurs NaN\n",
    "nb_nan = nan_df.sum().sum()\n",
    "\n",
    "print(nb_nan)  # Affiche 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04900bea-b195-4188-a838-d3dc4398bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les colonnes à utiliser pour l'arbre de décision\n",
    "feature_cols = list(df_concat.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c5fa2-64ef-491b-951a-ca753665b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner la colonne cible pour l'arbre de décision\n",
    "target_col = df_concat.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddcec5-dfd6-42b7-b145-7116fef77df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le DataFrame en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_concat[feature_cols], df_concat[target_col], test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace752d-2a6e-4ec8-8695-ff3c6c304f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import Random Forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb46c6-0efb-4cc5-b544-19a6d788f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid\n",
    "#n_estimators = [10, 100,200]\n",
    "n_estimators=[100]\n",
    "#max_depth = [2,3,4]\n",
    "#max_depth = [20]\n",
    "grid_space={'max_depth':[3,5,10,None],\n",
    "              'n_estimators':[10,100,200],\n",
    "              'max_features':[1,3,5,7],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }\n",
    "\n",
    "\n",
    "#params = {'max_features': ['sqrt', 'log2', None],'n_estimators': [25, 50, 100, 150],'max_depth': [3, 6, 9],'max_leaf_nodes': [3, 6, 9]}\n",
    "params = {\"n_estimators\":[100], \"max_depth\":[10], 'max_features':[7],'min_samples_leaf':[1],'min_samples_split':[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d9490-f7f4-4088-ade4-4b32574d8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier \n",
    "\n",
    "rfc = yClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae154e-6751-45fe-b5ca-d195fad33bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc_cv = GridSearchCV(rfc,params, scoring=scorer, n_jobs=-1, verbose=1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805710bd-bb73-4d97-af1d-da976fd5b1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rfc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215ce3b-c522-4f70-8434-f7aa271ba466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rfc_cv.best_estimator_)\n",
    "print(f\"Best parameters: {rfc_cv.best_params_}\")\n",
    "print(rfc_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e97f86-a007-4bef-8880-560901f9a05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fit the model\n",
    "best_params = rfc_cv.best_params_\n",
    "best_rf= RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4d5d6-db57-4222-a6bb-3f20013f86f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = df_concat[target_col].unique()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815e20d-69b9-460f-8888-bdfbab6e935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the Test set results\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b365a15-84d4-4e31-a9df-b2a42c1058ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbde673-1d5e-45ba-bc43-19155036b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329e213-33cf-409e-a44d-2c7743a97908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix,display_labels=class_names)\n",
    "disp.plot(ax=ax, xticks_rotation=50, values_format='d')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7565992-b33a-424a-9492-7e849bad8998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_score(best_rf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(best_rf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a1e8e-fdd9-4cd2-83bb-6c5186a7457c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Créer un objet graphviz pour visualiser l'arbre de décision\n",
    "#dot_data = export_graphviz(best_rf, out_file=None, feature_names=feature_cols, filled=True, rounded=True, special_characters=True,class_names =class_names)\n",
    "dot_data = export_graphviz(best_rf.estimators_[0], out_file=None, feature_names=feature_cols,\n",
    "                           class_names=class_names, filled=True, rounded=True,\n",
    "                           special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c619d2-ff63-4872-a48b-c7dbdfae39ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformer le fichier .dot en une image représentant l'arbre de décision\n",
    "\n",
    "display(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799b69d-dd0a-43e9-810d-cea7d3b995bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd656ea-2b0a-4419-bfea-650fe3e4581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le graphique dans un fichier PNG\n",
    "#graph.render(filename='random_forest_tree', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df6cff-a11d-493e-9674-ec6aa5db956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "feature_scores = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "print(feature_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c254ab-e15a-4925-85cb-7b21f5b95909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_i = list(zip(X_train.columns,best_rf.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f57f8-4575-4aff-9edc-dc3a96c44da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation feature\n",
    "perm_importance = permutation_importance(best_rf, X_test, y_test)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b740a5-7d7f-4753-9072-271ac3a503de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a673b5-da7f-43df-8a55-84df0d837e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    best_rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X_train.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e92bc-3a09-4991-9289-8bc71d06b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross val\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "K_fold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b509da-94f7-4910-bffe-a0027a3b6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve    \n",
    "\n",
    "scores = cross_val_score(best_rf, X_train, y_train, cv=K_fold, \n",
    "                        n_jobs=4, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "round(np.mean(scores)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6e640-96ec-435a-ae08-717917ce537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = best_rf.predict_proba(X_test)\n",
    "print(y_score)\n",
    "print('roc_auc_score for Random forest: ', roc_auc_score(y_test, y_score,multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dce408-ff3c-47a9-9373-5ce9a2e9650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3ca51-ab62-4cdf-a515-375ff42a04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(estimator = best_rf ,title = \"Random forest - Learning Curve\",\n",
    "                    X = X_train, y = y_train, cv = K_fold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8300a3-931a-471e-a21e-2b6c2b030c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_concat[feature_cols]\n",
    "y=df_concat[target_col]\n",
    "random_state = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b19fdf-814b-4bb5-ae9f-4379b94c178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "print(f\"{n_classes} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e33d1-dfed-4fc0-8d05-7beac1258397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "print(y_onehot_test.shape)  # (n_samples, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204650f-c389-4a5a-8077-482c698c0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test.ravel(),\n",
    "    y_score.ravel(),\n",
    "    name=\"micro-average OvR\",\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe2f45-f5c3-473a-9e80-607ebad8179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "micro_roc_auc_ovr = roc_auc_score(\n",
    "    y_test,\n",
    "    y_score,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"micro\",\n",
    ")\n",
    "\n",
    "print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24cc966-4943-4662-a30c-2217cc2d4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_roc_auc_ovr = roc_auc_score(\n",
    "    y_test,\n",
    "    y_score,\n",
    "    multi_class=\"ovr\",\n",
    "    average=\"macro\",\n",
    ")\n",
    "\n",
    "print(f\"Macro-averaged One-vs-Rest ROC AUC score:\\n{macro_roc_auc_ovr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1ce80-0a02-40b7-88f6-a25124cb0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['micro']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c3e05-ccfa-4ea7-a510-5194c6d4f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_onehot_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "# Interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])  # linear interpolation\n",
    "\n",
    "# Average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = fpr_grid\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "print(f\"Macro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['macro']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668313bf-59cb-4bca-aed7-9ffbcd3a56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=f\"macro-average ROC curve (AUC = {roc_auc['macro']:.2f})\",\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_score[:, class_id],\n",
    "        name=f\"ROC curve for {class_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"ROC curve for chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512285b6-3dc6-4082-97c0-19085f6b1c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ac577-7986-4bc5-a27a-ce999d481171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
